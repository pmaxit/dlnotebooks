{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nlp.datasets.cmudict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP deep learning\n",
    "\n",
    "This notebook contains some utilities to help us in NLP deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchtext is a NLP processing library from Facebook. It's easy to use, efficient and handle most of the use cases to convert text into numbers, a fundamental step in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "import datasets\n",
    "import torchtext\n",
    "import csv\n",
    "\n",
    "URL= 'https://raw.githubusercontent.com/cmusphinx/cmudict/master/cmudict.dict'\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "Books are a rich source of both fine-grained information, how a character, \\\n",
    "an object or a scene looks like, as well as high-level semantics, what \\\n",
    "someone is thinking, feeling and how these states evolve through a story.\\\n",
    "This work aims to align books to their movie releases in order to provide\\\n",
    "rich descriptive explanations for visual content that go semantically far\\\n",
    "beyond the captions available in current datasets. \\\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@InProceedings{Zhu_2015_ICCV,\n",
    "    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},\n",
    "    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},\n",
    "    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},\n",
    "    month = {December},\n",
    "    year = {2015}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "_PUNCTUATIONS = set([\n",
    "    \"!EXCLAMATION-POINT\",\n",
    "    \"\\\"CLOSE-QUOTE\",\n",
    "    \"\\\"DOUBLE-QUOTE\",\n",
    "    \"\\\"END-OF-QUOTE\",\n",
    "    \"\\\"END-QUOTE\",\n",
    "    \"\\\"IN-QUOTES\",\n",
    "    \"\\\"QUOTE\",\n",
    "    \"\\\"UNQUOTE\",\n",
    "    \"#HASH-MARK\",\n",
    "    \"#POUND-SIGN\",\n",
    "    \"#SHARP-SIGN\",\n",
    "    \"%PERCENT\",\n",
    "    \"&AMPERSAND\",\n",
    "    \"'END-INNER-QUOTE\",\n",
    "    \"'END-QUOTE\",\n",
    "    \"'INNER-QUOTE\",\n",
    "    \"'QUOTE\",\n",
    "    \"'SINGLE-QUOTE\",\n",
    "    \"(BEGIN-PARENS\",\n",
    "    \"(IN-PARENTHESES\",\n",
    "    \"(LEFT-PAREN\",\n",
    "    \"(OPEN-PARENTHESES\",\n",
    "    \"(PAREN\",\n",
    "    \"(PARENS\",\n",
    "    \"(PARENTHESES\",\n",
    "    \")CLOSE-PAREN\",\n",
    "    \")CLOSE-PARENTHESES\",\n",
    "    \")END-PAREN\",\n",
    "    \")END-PARENS\",\n",
    "    \")END-PARENTHESES\",\n",
    "    \")END-THE-PAREN\",\n",
    "    \")PAREN\",\n",
    "    \")PARENS\",\n",
    "    \")RIGHT-PAREN\",\n",
    "    \")UN-PARENTHESES\",\n",
    "    \"+PLUS\",\n",
    "    \",COMMA\",\n",
    "    \"--DASH\",\n",
    "    \"-DASH\",\n",
    "    \"-HYPHEN\",\n",
    "    \"...ELLIPSIS\",\n",
    "    \".DECIMAL\",\n",
    "    \".DOT\",\n",
    "    \".FULL-STOP\",\n",
    "    \".PERIOD\",\n",
    "    \".POINT\",\n",
    "    \"/SLASH\",\n",
    "    \":COLON\",\n",
    "    \";SEMI-COLON\",\n",
    "    \";SEMI-COLON(1)\",\n",
    "    \"?QUESTION-MARK\",\n",
    "    \"{BRACE\",\n",
    "    \"{LEFT-BRACE\",\n",
    "    \"{OPEN-BRACE\",\n",
    "    \"}CLOSE-BRACE\",\n",
    "    \"}RIGHT-BRACE\",\n",
    "])\n",
    "\n",
    "_alt_re = re.compile(r'[^a-zA-Z]+')\n",
    "\n",
    "class CMUDict(datasets.GeneratorBasedBuilder):\n",
    "    \"\"\" CMU Dict dataset \"\"\"\n",
    "    \n",
    "    BUILDER_CONFIGS=[\n",
    "        datasets.BuilderConfig(name='cmu3',description='cmu phonemes to words', version='1.0.0')\n",
    "    ]\n",
    "    \n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            description = _DESCRIPTION,\n",
    "            features = datasets.Features(\n",
    "                {\n",
    "                    'word': datasets.Value(\"string\"),\n",
    "                    'word_length': datasets.Value('uint8'),\n",
    "                    'phoneme': datasets.Sequence(datasets.Value(\"string\"))\n",
    "                }\n",
    "            ),\n",
    "            supervised_keys=None,\n",
    "            citation=_CITATION\n",
    "        )\n",
    "    \n",
    "    def _vocab_text_gen(self, archive):\n",
    "        for _,ex in self._generate_examples(archive):\n",
    "            yield ex['text']\n",
    "            \n",
    "    def _split_generators(self, dl_manager):\n",
    "        data_dir = dl_manager.download_and_extract(URL)\n",
    "        return [\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.TRAIN, \n",
    "                gen_kwargs={'filepath': data_dir, 'split': 'train'}\n",
    "            ),\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.VALIDATION,\n",
    "                gen_kwargs={'filepath': data_dir, 'split': 'validation'}\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def _generate_examples(self, filepath, split='train'):\n",
    "        with open(filepath, encoding='utf-8') as csv_file:\n",
    "            with open(filepath, encoding='utf-8') as f:\n",
    "                for _id, line in enumerate(f):\n",
    "                    if not line or line.startswith(';;;'):  # ignore comments\n",
    "                        continue\n",
    "                    word, *phones = line.strip().split(' ')\n",
    "                    if word in _PUNCTUATIONS:\n",
    "                        if exclude_punctuations:\n",
    "                            continue\n",
    "                            \n",
    "                        if word.startswith(\"...\"):\n",
    "                            word = '...'\n",
    "                    \n",
    "                        if word.startswith(\"--\"):\n",
    "                            word = '--'\n",
    "                        else:\n",
    "                            word = word[0]\n",
    "                            \n",
    "                    # if word has multiple pronounciations, there will be (number appended to it)\n",
    "                    # for example, DATAPOINTS DATAPOINTS(1)\n",
    "                    # regular expression _alt_re removes (1) and change DATAPOINTS(1) to DATAPOINTS\n",
    "                    word = re.sub(_alt_re, '', word)\n",
    "                    yield _id, {\n",
    "                        'word': word,\n",
    "                        'word_length': len(word),\n",
    "                        'phoneme': phones\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataset.ipynb.\n",
      "Converted 01_seq2seq.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
