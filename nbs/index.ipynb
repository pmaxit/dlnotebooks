{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mllib.nlp.datasets.cmudict import CMUDict\n",
    "from datasets import load_dataset\n",
    "from mllib.nlp.seq2seq import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cmu_dict/cmu2 to /root/.cache/huggingface/datasets/cmu_dict/cmu2/1.0.0/3b3904aac9acadebed008a26558832f94749da39e2cd1ecee825720fd34a1da1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9109319f5d214839925cc87becf19869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/919k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cmu_dict downloaded and prepared to /root/.cache/huggingface/datasets/cmu_dict/cmu2/1.0.0/3b3904aac9acadebed008a26558832f94749da39e2cd1ecee825720fd34a1da1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce73ea8db4884a73a9ad0aec9dea256b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset('/notebooks/dlnotebooks/mllib/nlp/datasets/cmudict.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = ds['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'preempted',\n",
       " 'word_length': 9,\n",
       " 'phoneme': ['P', 'R', 'IY0', 'EH1', 'M', 'P', 'T', 'IH0', 'D']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data with map inspired by `tf.dataset.map` map method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('preempted', ['P', 'R', 'IY0', 'EH1', 'M', 'P', 'T', 'IH0', 'D'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['train']['word'][0], train_test['train']['phoneme'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108124lines [00:00, 531019.42lines/s]\n",
      "108124lines [00:00, 547361.56lines/s]\n"
     ]
    }
   ],
   "source": [
    "phoneme_vocab = build_vocab_from_iterator(train_test['train']['phoneme'])\n",
    "word_vocab = build_vocab_from_iterator(train_test['train']['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 18, 11]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vocab.lookup_indices(['a','b','c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_single_example(word_tokens, phoneme, word_length):\n",
    "    # Heree you can add variety of operations, Not only is it tokenize\n",
    "    # The object that this function handles, Namely dataset this data type, adopt featuer\n",
    "    \n",
    "    src = word_vocab.lookup_indices(word_tokens)\n",
    "    trg = phoneme_vocab.lookup_indices(phoneme)\n",
    "\n",
    "    return src, trg, word_length\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \n",
    "    batch_size = len(batch['word'])\n",
    "    out = [process_single_example(*tokens) for tokens in zip(batch['word'], batch['phoneme'], batch['word_length'])]\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'src': [b[0] for b in out],\n",
    "        'trg': [b[1] for b in out],\n",
    "        'src_len': [b[2] for b in out],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ec9e456dd48ed9d095353ee20cc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3379 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0641ca55834f70825009dce32e7d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/845 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_processed = train_test.map(collate_batch, remove_columns=['word','word_length','phoneme'], \n",
    "                        batch_size= BATCH_SIZE,\n",
    "                           batched=True).with_format('pytorch', output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': tensor([18,  8,  9,  9,  5,  7, 16]),\n",
       " 'trg': tensor([15, 19,  6, 10, 25]),\n",
       " 'src_len': tensor(7)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_processed['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    \n",
    "    def pad(xs):\n",
    "        return torch.nn.utils.rnn.pad_sequence(xs, batch_first=True)\n",
    "    \n",
    "    src = [b['src'] for b in batch]\n",
    "    trg = [b['trg'] for b in batch]\n",
    "    src_len = [b['src_len'] for b in batch]\n",
    "    \n",
    "    return {\n",
    "        'src': pad(src), \n",
    "        'trg' : pad(trg), \n",
    "        'src_len' : src_len\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoader(ds_processed['train'], shuffle=True, collate_fn=pad_collate, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rids R,IH1,D,Z tensor(4)\n",
      "dershem D,ER1,SH,IH0,M tensor(7)\n",
      "botello B,OW0,T,EH1,L,OW0 tensor(7)\n",
      "brimmed B,R,IH1,M,D tensor(7)\n",
      "blinds B,L,AY1,N,D,Z tensor(6)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# checking\n",
    "def decode_word(lst):\n",
    "    return ''.join([word_vocab.itos[l] for l in lst])\n",
    "\n",
    "def decode_phoneme(lst):\n",
    "    return ','.join([phoneme_vocab.itos[l] for l in lst])\n",
    "\n",
    "indices = random.sample(range(10,1000), 5 )\n",
    "\n",
    "for l in indices:\n",
    "    src = decode_word(ds_processed['train']['src'][l])\n",
    "    trg = decode_phoneme(ds_processed['train']['trg'][l])\n",
    "    src_len = ds_processed['train']['src_len'][l]\n",
    "    print(src, trg, src_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "logger = TensorBoardLogger('tb_logs', name='my_model')\n",
    "trainer = pl.Trainer(callbacks=[lr_monitor],max_epochs=1, gpus=1, logger=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
